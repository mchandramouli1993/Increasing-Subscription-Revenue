{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import glob\n",
    "import string\n",
    "import nltk\n",
    "import os\n",
    "from os import listdir\n",
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import csv\n",
    "import math, random\n",
    "from collections import defaultdict, Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test cell for coding experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "path = 'D:\\\\uncc2018\\\\Text\\\\*.txt'  \n",
    "files=glob.glob(path)   \n",
    "for file in files:     \n",
    "    f = open(file, encoding=\"ascii\", errors=\"surrogateescape\")\n",
    "    text = f.read()\n",
    "    print('Cleaning the file:' + os.path.basename(f.name))\n",
    "    #remove awkward spacing around special characters - there are splits like \"de- scribe\"\n",
    "    text = re.sub(r'[-]\\s\\n', '', text)\n",
    "    text = re.sub(r'[-]\\n', '', text)\n",
    "    # split into words\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "    import string\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # stemming of words\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "    # writing the cleaned data to clean data directory\n",
    "    cleanedFilePath = \"D:\\\\uncc2018\\\\cleanedtext\\\\\" + os.path.basename(f.name)\n",
    "    cleanedFile = open(cleanedFilePath, 'w')\n",
    "    cleanedFile.writelines([\"%s\\n\" % word  for word in stemmed])\n",
    "    cleanedFile.close()\n",
    "print('Clean up completed - Refer to the cleanedText directory for data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging files\n",
    "filenames = [fname for fname in os.listdir('D:\\\\uncc2018\\\\cleanedtext\\\\')] \n",
    "with open('D:\\\\uncc2018\\\\output\\\\WordCloudBase.txt','w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open('D:\\\\uncc2018\\\\cleanedtext\\\\' + fname) as infile:\n",
    "                lines = infile.readlines()\n",
    "                mystr = ' '.join([line.strip() for line in lines if len(line) > 3])\n",
    "                outfile.write(mystr + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executing wordcloud\n",
    "figure = plt.figure(figsize = (10,10))\n",
    "with codecs.open('D:\\\\uncc2018\\\\output\\\\WordCloudBase.txt', \"r\", encoding='utf-8') as abs:\n",
    "        text = abs.read()\n",
    "        wc = WordCloud(background_color=\"white\")  \n",
    "        wc.generate(text)\n",
    "        plt.imshow(wc, aspect='auto')\n",
    "        plt.axis(\"off\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term-document matrix\n",
    "from collections import Counter\n",
    "csvfile = 'D:\\\\uncc2018\\\\output\\\\term_document_matrix.csv'\n",
    "header_count = 1\n",
    "f = open(csvfile, 'w+').close()\n",
    "with codecs.open('D:\\\\uncc2018\\\\output\\\\WordCloudBase.txt', \"r\", encoding='utf-8') as abs:\n",
    "    read_abs = abs.read()\n",
    "    words = read_abs.split()\n",
    "    Counter = Counter(words)\n",
    "    most_occur = Counter.most_common(50)\n",
    "    word_list= [i[0] for i in most_occur]\n",
    "    header = ['Document Index'] + word_list\n",
    "    doc = re.split(r'\\n', read_abs)\n",
    "    i = 1\n",
    "    word_counts = []\n",
    "    for para in doc:\n",
    "        int_count = []\n",
    "        word_count_list =[]\n",
    "        for k in range(0,(len(word_list))):\n",
    "            int_count = sum(1 for match in re.finditer(word_list[k], para))\n",
    "            word_count_list = word_count_list + [int_count]\n",
    "        word_counts = [i] + word_count_list\n",
    "        with open(csvfile, 'w', newline='') as myfile:\n",
    "            wr = csv.writer(myfile)\n",
    "            if header_count == 1:\n",
    "                wr.writerow(header)\n",
    "                header_count = 0\n",
    "            wr.writerow(word_counts)\n",
    "        i = i + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducing the document scope for Topic Modeling\n",
    "#We ended up not using this because it blurrs the distiction between documents too much\n",
    "#with open('D:\\\\uncc2018\\\\output\\\\TMBase.txt','w+',newline='') as txt:\n",
    "    #with codecs.open('D:\\\\uncc2018\\\\output\\\\WordCloudBase.txt', \"r\", encoding='utf-8') as abs:\n",
    "        #read_abs = abs.read()\n",
    "        #remove = '|'.join(word_list)\n",
    "        #print(remove)\n",
    "        #out = re.sub(r'\\b(?!perform|manag|firm|use|employe|studi|journal|measur|environment|practic|effect|research|resourc|variabl|social|corpor|result|market|product|model|organiz|relationship|busi|industri|may|human|organ|posit|relat|compani|level|work|strategi|turnov|respons|also|strateg|custom|develop|differ|data|csr|report|new|reput|tabl|valu|inform|analysi|control)\\b\\w+','',read_abs)\n",
    "        #out = re.sub(' +',' ',out)\n",
    "        #txt.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions for Gibbs sampling and Topic modeling\n",
    "#\n",
    "def roll_a_die():\n",
    "    return random.choice([1,2,3,4,5,6])\n",
    "\n",
    "def direct_sample():\n",
    "    d1 = roll_a_die()\n",
    "    d2 = roll_a_die()\n",
    "    return d1, d1 + d2\n",
    "\n",
    "def random_y_given_x(x):\n",
    "    \"\"\"equally likely to be x + 1, x + 2, ... , x + 6\"\"\"\n",
    "    return x + roll_a_die()\n",
    "\n",
    "def random_x_given_y(y):\n",
    "    if y <= 7:\n",
    "        # if the total is 7 or less, the first die is equally likely to be\n",
    "        # 1, 2, ..., (total - 1)\n",
    "        return random.randrange(1, y)\n",
    "    else:\n",
    "        # if the total is 7 or more, the first die is equally likely to be\n",
    "        # (total - 6), (total - 5), ..., 6\n",
    "        return random.randrange(y - 6, 7)\n",
    "\n",
    "def gibbs_sample(num_iters=100):\n",
    "    x, y = 1, 2 # doesn't really matter\n",
    "    for _ in range(num_iters):\n",
    "        x = random_x_given_y(y)\n",
    "        y = random_y_given_x(x)\n",
    "    return x, y\n",
    "\n",
    "def compare_distributions(num_samples=1000):\n",
    "    counts = defaultdict(lambda: [0, 0])\n",
    "    for _ in range(num_samples):\n",
    "        counts[gibbs_sample()][0] += 1\n",
    "        counts[direct_sample()][1] += 1\n",
    "    return counts\n",
    "\n",
    "def sample_from(weights):\n",
    "    total = sum(weights)\n",
    "    rnd = total * random.random()       # uniform between 0 and total\n",
    "    for i, w in enumerate(weights):\n",
    "        rnd -= w                        # return the smallest i such that\n",
    "        if rnd <= 0: return i           # sum(weights[:(i+1)]) >= rnd\n",
    "\n",
    "def p_topic_given_document(topic, d, alpha=0.1):\n",
    "    \"\"\"the fraction of words in document _d_\n",
    "    that are assigned to _topic_ (plus some smoothing)\"\"\"\n",
    "\n",
    "    return ((document_topic_counts[d][topic] + alpha) /\n",
    "            (document_lengths[d] + K * alpha))\n",
    "\n",
    "def p_word_given_topic(word, topic, beta=0.1):\n",
    "    \"\"\"the fraction of words assigned to _topic_\n",
    "    that equal _word_ (plus some smoothing)\"\"\"\n",
    "\n",
    "    return ((topic_word_counts[topic][word] + beta) /\n",
    "            (topic_counts[topic] + W * beta))\n",
    "\n",
    "def topic_weight(d, word, k):\n",
    "    \"\"\"given a document and a word in that document,\n",
    "    return the weight for the k-th topic\"\"\"\n",
    "\n",
    "    return p_word_given_topic(word, k) * p_topic_given_document(k, d)\n",
    "\n",
    "def choose_new_topic(d, word):\n",
    "    return sample_from([topic_weight(d, word, k)\n",
    "                        for k in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic Modeling\n",
    "# If an error with \"Counter not callable\" appears, rerun the library import cell\n",
    "from collections import defaultdict, Counter\n",
    "abs = codecs.open('D:\\\\uncc2018\\\\output\\\\WordCloudBase.txt', \"r\", encoding='utf-8')\n",
    "docs = abs.readlines()\n",
    "documents = [line.split() for line in docs]\n",
    "\n",
    "K = 2\n",
    "\n",
    "document_topic_counts = [Counter() for _ in documents]\n",
    "topic_word_counts = [Counter() for _ in range(K)]\n",
    "topic_counts = [0 for _ in range(K)]\n",
    "document_lengths = [len(d) for d in documents]\n",
    "\n",
    "distinct_words = set(word for document in documents for word in document)\n",
    "W = len(distinct_words)\n",
    "print(distinct_words)\n",
    "D = len(documents)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic Modeling 2\n",
    "random.seed(0)\n",
    "document_topics = [[random.randrange(K) for word in document]\n",
    "                   for document in documents]\n",
    "\n",
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1\n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1\n",
    "\n",
    "for iter in range(25):\n",
    "    for d in range(D):\n",
    "        for i, (word, topic) in enumerate(zip(documents[d],\n",
    "                                              document_topics[d])):\n",
    "\n",
    "            # remove this word / topic from the counts\n",
    "            # so that it doesn't influence the weights\n",
    "            document_topic_counts[d][topic] -= 1\n",
    "            topic_word_counts[topic][word] -= 1\n",
    "            topic_counts[topic] -= 1\n",
    "            document_lengths[d] -= 1\n",
    "\n",
    "            # choose a new topic based on the weights\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "\n",
    "            # and now add it back to the counts\n",
    "            document_topic_counts[d][new_topic] += 1\n",
    "            topic_word_counts[new_topic][word] += 1\n",
    "            topic_counts[new_topic] += 1\n",
    "            document_lengths[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Modeling 3\n",
    "csvfile2 = 'D:\\\\uncc2018\\\\output\\\\TMK2_full.csv'\n",
    "for k, word_counts in enumerate(topic_word_counts):\n",
    "    for word, count in word_counts.most_common():\n",
    "        with open(csvfile2, 'a+', newline='') as myfile2:\n",
    "            wr = csv.writer(myfile2)\n",
    "            if count > 800: \n",
    "                wr.writerow([k, word, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic modeling 4 - final step\n",
    "topic_names = [\"Result-oriented\",\"Socially Responsible\"]\n",
    "\n",
    "csvfile3 = 'D:\\\\uncc2018\\\\output\\\\TMwDocs.csv'\n",
    "for document, topic_counts in zip(documents, document_topic_counts):\n",
    "    with open(csvfile3, 'a+', newline='') as myfile3:\n",
    "        wr = csv.writer(myfile3)\n",
    "        for topic, count in topic_counts.most_common():\n",
    "            if count > 0:\n",
    "                wr.writerow([topic_names[topic], count])\n",
    "        wr.writerow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.84\n",
      "[[29  6]\n",
      " [ 4 24]]\n",
      "\n",
      "Gaussian Naive Bayes model accuracy: 0.8412698412698413\n",
      "[[33  2]\n",
      " [ 3 25]]\n"
     ]
    }
   ],
   "source": [
    "#Modeling - Logistic regression and Bayes\n",
    "#If you get \"numpy object not callable\" error, rerun the libraries cell\n",
    "from sklearn.metrics import confusion_matrix\n",
    "regdata = pd.read_csv('D:\\\\uncc2018\\\\output\\\\modelinput.csv')\n",
    "target=['class']\n",
    "predict=['perform','manag','firm','use','employe','studi','journal','measur','environment','practic','effect','research','resourc','variabl','social','corpor','result','market','product','model','organiz','relationship','busi','industri','may','human','organ','posit','relat','compani','level','work','strategi','turnov','respons','also','strateg','custom','develop','differ','data','csr','report','new','reput','tabl','valu','inform','analysi', 'control']\n",
    "x=regdata[predict]\n",
    "y=regdata[target]\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)\n",
    "logreg.fit(x_train, y_train.values.ravel())\n",
    "y_pred = logreg.predict(x_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "model = MultinomialNB().fit(x_train, y_train.values.ravel())\n",
    "predicted = model.predict(x_test)\n",
    "print(\"Gaussian Naive Bayes model accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
